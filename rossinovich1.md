# [Windows NT Architecture, Part 1](https://www.itprotoday.com/compute-engines/windows-nt-architecture-part-1)
Mark Russinovich | Feb 28, 1998

The design and construction of an innovative operating system

Windows NT's architecture influences everything from its API to its performance. In the late 1980s, Microsoft charged NT's developers with creating a new operating system, and the company mandated a hefty list of requirements to make NT the world's dominant desktop and enterprise-level operating system. NT's developers faced the constraints of supporting backward compatibility with DOS and Windows 3.x, as well as supporting a laundry list of capabilities intended to ensure NT's long-term success. What NT's developers produced was an operating system that made use of 1980s cutting-edge technologies but had roots in earlier operating systems. NT met Microsoft's broad requirement list, and that fact positioned NT to become widely adopted, no matter which of the popular operating system API sets, processor types, or network interfaces won market dominance.

This month I provide the first part of a two-part primer on NT architecture. I'll describe some of the design requirements that were goals for NT from the start. Then I'll outline in broad strokes the components that make up NT's base operating system and describe how they fit together. I conclude this month with a close look at NT operating system environments and system services. Next month I'll take an in-depth look at the NT Executive, Kernel, and hardware abstraction layer (HAL).

A Brief History of NT's Development
During NT's development period, from 1988 to 1993, the computing world was different from how it is today. DOS was the predominant PC operating system, and both Windows and OS/2 were gaining momentum. Servers and scientific and engineering workstations ran UNIX exclusively. Because all these operating systems were popular, Microsoft built support in NT for DOS, Windows 3.x, OS/2, and POSIX. This support created an upgrade and compatibility mode in NT for DOS and Windows users, and also enabled OS/2 and POSIX users to migrate to NT.

Microsoft realized that although NT's DOS and Windows 3.x support made its PC customers happy, enterprise-level (which at that time meant 32-bit) customers were more interested in the POSIX and OS/2 32-bit APIs. Microsoft saw that if it wanted to capture enterprise-level customers, it would have to develop its own 32-bit API. Thus, Win32, Microsoft's answer to OS/2 and POSIX, became NT's primary API.

Throughout NT's development period, most PCs used Intel's x86 processor. Several RISC processors competed for dominance of UNIX boxes: IBM and Motorola's PowerPC, MIPS processors, and Digital's Alpha. To keep its PC customer base, as well as to accommodate the desires of high-end users, Microsoft decided to make NT as portable as possible, and the company designed NT to run out of the box on any of the RISC processor chips. Microsoft reasoned that NT's portability across different processors would ensure its viability regardless of which chip came out on top in the market.

Windows 3.1 had no native networking support, and Windows 3.11's networking capabilities were cumbersome and relatively slow. As a result, Microsoft felt Novell NetWare's sting. Microsoft intended to avoid repeating these networking mistakes, and it outfitted NT with support for most of the APIs and networking protocols that were in widespread use in the 1980s. Those APIs included NetBIOS, remote procedure call (RPC), file server and redirector (Server Message Block­SMB), mail slots, named pipes, and Berkeley sockets. The protocols included TCP/IP, NetBEUI (Microsoft's LanManager protocol), IPX/SPX (Novell's NetWare protocol), AppleTalk Data Link Control (DLC), and SNA. By including protocols in NT that its competitors owned (i.e., AppleTalk and IPX/SPX), Microsoft opened the door to sites that were dominated by Macintosh or NetWare.

In addition to these high-level requirements, Microsoft included two important low-level operating system capabilities in NT. First, NT's developers designed its security subsystem as a centralized module that can be easily and thoroughly validated. This security configuration earned NT a C2 security rating.

Second, its developers gave NT a multitasking preemptive-scheduling system. Neither DOS nor Windows 3.x is capable of true multitasking with preemptive scheduling. Without add-on software, DOS can execute only one program, or task, at a time. Windows 3.x can execute several programs concurrently, but they must be well-behaved; that is, each program must be aware that other programs may need to run, and it must therefore yield the machine at regular intervals. This design means that a buggy or malicious program can halt the computer simply by entering an infinite loop in which it never yields. In NT, a centralized scheduling authority doles out CPU time to programs that need it. Once a program's turn has ended, the scheduler has the power to preempt it and give another program a turn.

Microsoft wanted NT to incorporate one final major feature: It had to be truly 32-bit and provide protected address spaces, à la UNIX. DOS and Windows 3.x are 16-bit operating systems. Programs running on them cannot easily access large amounts of memory. Using 32-bit addressing enables programs on NT to access 4GB (232 bytes) of memory efficiently. (A 64-bit version of NT is due for release within 2 years, and it will let programs address even larger amounts of memory efficiently.)

NT's developers ensured 32-bit system reliability by including protected address spaces in NT. Every program in Windows 3.x has a region of memory assigned to it. However, any program can scribble on the memory regions that belong to any other program--a program can even scribble on memory regions reserved for Windows, with disastrous effects. But with the protected address spaces in NT, all programs are confined to their memory regions and have no access (unless by permission) to the memory spaces of other applications. NT also prevents applications from accessing parts of memory owned by the Executive and by kernel-mode portions of the operating system, including device drivers.

An Overview of NT Architecture
Let's begin our look at NT's architecture by discussing the distinction between user mode and kernel mode. I discussed the user mode/kernel mode concept in "Inside the Blue Screen," December 1997, and I'll summarize it here (Figure 1 shows this architecture). User mode is the least-privileged mode NT supports; it has no direct access to hardware and only restricted access to memory. For example, when programs such as Word and Lotus Notes execute in user mode, they are confined to sandboxes with well-defined restrictions. They don't have direct access to hardware devices, and they can't touch parts of memory that are not specifically assigned to them. Kernel mode is a privileged mode. Those parts of NT that execute in kernel mode, such as device drivers and subsystems such as the Virtual Memory Manager, have direct access to all hardware and memory.

Other operating systems, including Windows 3.1 and UNIX, also use privileged and nonprivileged modes. What makes NT unique is where it draws the line between the two. NT is sometimes referred to as a microkernel-based operating system. Microkernel-based operating systems developed from university research in the mid-1980s. The idea behind the pure microkernel concept is that all operating system components except a small core (the microkernel) execute as user-mode processes, just as word processors and spreadsheets do. But the core components in the microkernel execute in privileged mode, so they access hardware directly. Figure 2, page 64, shows a pure microkernel operating system design.

Microkernel architecture gives a system configurability and fault tolerance. Because an operating system subsystem like the Virtual Memory Manager runs as a distinct program in microkernel design, a different implementation that exports the same interface can replace it. If the Virtual Memory Manager fails, thanks to the fault-tolerance possible in a microkernel design, the operating system can restart it with minimal effect on the rest of the system. In monolithic operating system design (e.g., DOS and Windows 3.1), the entire operating system must be rebuilt to change any subsystem. Figure 3, page 64, shows a monolithic operating system design. If the Virtual Memory Manager has a bug in a monolithic system, the bug is likely to bring down the machine.

A disadvantage to pure microkernel design is slow performance. Every interaction between operating system components in microkernel design requires an interprocess message. For example, if the Process Manager requires the Virtual Memory Manager to create an address map for a new process, it must send a message to the Virtual Memory Manager. In addition to the overhead costs of creating and sending messages, the interprocess message requirement results in two context switches: the first from the Process Manager to the Virtual Memory Manager, and the second back to the Process Manager after the Virtual Memory Manager carries out the request.

NT takes a unique approach, known as modified microkernel, that falls between pure microkernel and monolithic design. In NT's modified microkernel design, operating system environments execute in user mode as discrete processes, including DOS, Win16, Win32, OS/2, and POSIX (DOS and Win16 are not shown in Figure 1). The basic operating system subsystems, including the Process Manager and the Virtual Memory Manager, execute in kernel mode, and they are compiled into one file image. These kernel-mode subsystems are not separate processes, and they can communicate with one another by using function calls for maximum performance.

NT's user-mode operating system environments implement separate operating system APIs. The degree of NT support for each environment varies, however. Support for DOS is limited to the DOS programs that do not attempt to access the computer's hardware directly. OS/2 and POSIX support stops short of user-interface functions and the advanced features of the APIs. Win32 is really the official language of NT, and it's the only API Microsoft has expanded since NT was first released.

NT's operating system environments rely on services that the kernel mode exports to carry out tasks that they can't carry out in user mode. The services invoked in kernel mode are known as NT's native API. This API is made up of about 250 functions that NT's operating systems access through software-exception system calls. A software-exception system call is a hardware-assisted way to change execution modes from user mode to kernel mode; it gives NT control over the data that passes between the two modes.

Native API requests are executed by functions in kernel mode, known as system services. To carry out work, system services call on functions in one or more components of NT's Executive. As shown in Figure 1, the Executive components include the I/O Manager, Object Manager, Security Reference Monitor, Process Manager, Local Procedure Call Facility, and Virtual Memory Manager. Each Executive component has a specific operating system responsibility. Device drivers are dynamically added NT components that work closely with the I/O Manager to connect NT to specific hardware devices, such as disks and input devices.

A handful of other components are not usually described in Microsoft's NT architecture literature (e.g., the Cache Manager and the Configuration Manager). I'll describe these components in Part 2 of this primer.

NT's Executive components use basic hardware functionality implemented in the microkernel. The microkernel, which is known in NT as the Kernel, contains the scheduler. The Kernel also manages the Executive's use of NT's hardware and software interrupt handlers and exports synchronization primitives.

Device drivers and the Kernel use the HAL to interact with the computer's hardware. The HAL exports its own API, which translates abstract data into processor-specific commands. NT is portable across processor types because processor-specific code is restricted to the Kernel and the HAL. This situation means that when NT is ported to a new processor, only the Kernel and the HAL must be converted. The rest of NT's code is written in C and C++ and can simply be recompiled for the new processor.

Those are the basics of NT's architecture. Now let's delve into NT's operating system environments and system services more deeply.

Operating System Environments
NT's operating system environments are implemented as client/server systems. As part of the compile process, applications are bound by a link-time binding to an operating system API that NT's operating system environments export. The link-time binding connects the application to the environment's client-side DLLs, which accomplish the exporting of the API. For example, a Win32 program is a client of the Win32 operating system environment server, so it is linked to Win32's client-side DLLs, including Kernel32.dll, gdi32.dll, and user32.dll. A POSIX program would be linked to the POSIX client-side DLL, psxdll.dll.

Client-side DLLs carry out tasks on behalf of their servers, but they execute as part of a client process. As Figure 4, page 66, shows, in some cases a client-side DLL can fully implement an API without having to call upon the help of the server; in other cases, the server must help out. The server's aid is usually necessary only when global information related to the environment must be updated. When the client-side DLL requires help from the server, the DLL sends a message known as a local procedure call (LPC) to the server. When the server completes the specified request and returns an answer, the DLL can complete the function and return control to the client. Both the client-side DLL and the server may use NT's native API when necessary. Operating system environment APIs augment the native API with additional functionality or semantics that are specific to themselves.

One example of an operating system environment API that the environment's server must service is a CreateProcess function, in which the server creates a relationship between the client process and a new process. To create such a relationship, the server's CreateProcess function must call NT's native API CreateProcess function. An example of an operating system environment API that does not require client-side DLL interaction with its server is the ReadFile function. The ReadFile function can be implemented entirely in the DLL with the aid of the native API's ReadFile function. Because the ReadFile function does not require the update of global information, the server 's help is not necessary.

Because some operating system environment APIs require messages between a client and its server, an assumption has developed that system calls in NT are expensive. However, NT's LPC facility is highly optimized and very efficient. Nevertheless, Microsoft removed the most LPC-intensive portion of NT 3.51's Win32 operating system environment. Figure 5 shows NT 3.51 Win32 architecture, and Figure 6 shows the change to this architecture in NT 4.0.

The Win32 environment includes graphics and user-interface functions, which are implemented in its graphics device interface (GDI) and User components. In NT 3.51, whenever a Win32 program makes a drawing or user-interface call, the GDI or User client-side DLLs make LPC calls to the Win32 server (CSRSS.EXE). Those LPC calls to the server cause Win32's sluggish performance--the bane of microkernel-based operating systems. In NT 4.0, the User and GDI components move from user mode into kernel mode as a new Executive subsystem, Win32K.SYS. When a drawing call is made, the client-side GDI's DLL makes a new native system call into kernel mode, where the request is carried out (Win32 native system calls didn't exist in NT 3.5x). There is no message passing and no context switches--just a switch from user mode to kernel mode and back. This optimization has a dramatic effect on the performance of Win32 applications.

System Services
System services export the native API from kernel mode so that user-mode portions of NT can use it. The native API is intended for use by operating system environments, but nothing prevents an application from bypassing the operating system environment API and accessing the native API directly. However, the native API is usually undocumented, is very similar to (but more cumbersome than) the Win32 API, and would not give an application privileges or powers its operating system environment would not give it.

System services have names that begin with Nt. For example, Win32 has an API function called CreateProcess, which the Win32 server handles. CreateProcess calls the native API function, NtCreateProcess. The parameter lists for both functions are similar; however, CreateProcess performs significant amounts of work on behalf of the environment. For instance, it sets up the process's environment variables and command line and fills in the process address map with the program to be executed. System services validate parameters that are passed from user mode and then usually call functions within Executive subsystems. For example, NtCreateProcess calls the Process Manager Executive subsystem, invoking its PsCreateProcess function. Most system services are short because they serve primarily as thin interfaces between user mode and Executive subsystems. There can be a one-for-one correspondence between Win32 calls and native calls, but many Win32 functions make more than one native call to carry out a task.

Figure 7 shows the flow of control when an application calls a native API function. Applications and operating system environments that use the native API access it through a DLL named ntdll.dll. This DLL is linked to every process in an NT system and consists of entry points for every system service. These entry points don't do much other than preparing variables and causing a system service software exception. The System Service Exception Handler in kernel mode is executed in response to system service exceptions, and it uses a number associated with the requested service to index the System Service Table and find the function that implements the service. Thus, adding a new system service requires updates of that table and ntdll.dll. Microsoft continues to add to the number of system services in NT, and almost two dozen new calls will appear in NT 5.0.

Stay Tuned
Next month I'll conclude our two-part primer on NT's architecture with a look at the Executive and a description of the responsibilities and capabilities of each of its subsystems. I'll also take you inside the Kernel and down into the HAL.
# [Windows NT Architecture, Part 2](https://www.itprotoday.com/compute-engines/windows-nt-architecture-part-2)
Mark Russinovich | Mar 31, 1998

NT's Executive, Kernel, and HAL

Last month I began a two-part primer on Windows NT architecture. This month I conclude with a description and discussion of the components that make up the NT Executive. I'll discuss the responsibilities of the Kernel and delve into one of the more mysterious elements of NT, the hardware abstraction layer (HAL).

The Executive
NT's Executive subsystems make up the meatiest layer in kernel mode, and they perform most of the functions traditionally associated with operating systems. Table 1 lists NT's Executive subsystems, and Figure 1, page 60, shows their position in NT's architecture. These subsystems have separate responsibilities and names, so you might think they are different processes. For example, when a program like Microsoft Word requests an operating-system service such as memory allocation, the flow of control proceeds from Word into kernel mode through NT's native system service interface. A system service handler for memory allocation then directly invokes the Virtual Memory Manager's allocation function. The requested allocation executes in the context of the process (Word) that requested it--there is no context switch to a different system process.

If you've seen the system process in NT's Performance Monitor (Perfmon), you might think that the Executive subsystems are different processes. However, the purpose of the system process in Perfmon is to own Executive threads (commonly called worker threads) that carry out work, usually of a background nature, for Executive subsystems. For example, the Cache Manager creates system process threads for lazy-write operations: Every few seconds the threads will flush dirty disk data from memory back to the disk. Because no user-mode application is associated with a system process, the user-mode portion of the system process' address map is not defined. And because the address map's user-mode portion does not change when a thread from the system process executes, the computer's address-mapping structures are not updated. This situation is different from a change from one application to another, in which case the user-mode portion of the address map would have to be changed from, say, Word's to Netscape's.

Just as NT doesn't assign Executive subsystems to different processes, NT doesn't place the Executive subsystems in different image files (an image file is an executable file). The ntoskrnl.exe file contains all NT Executive subsystems (except the Win32 subsystem, which is in win32k.sys) and the Kernel. NT loads the ntoskrnl.exe file during the system boot into the kernel-mode half of the virtual memory map.

Object Manager. The Object Manager, which I characterized in a previous column as probably the least known of NT's Executive subsystems (see "Inside NT's Object Manager," October 1997), is also one of the most important. An operating system's primary role is to manage a computer's physical and logical resources. Other Executive subsystems use the Object Manager to define and manage objects that represent resources. For example, through the Object Manager, the Process Manager defines a process object to track active processes. Table 2 lists the NT 4.0-defined objects and the kernel-mode subsystems that manage them.

The Object Manager performs object-management duties that include identification and reference counting. When an application opens a resource, the Object Manager either locates the associated object or creates a new object. Instead of returning an object pointer to the application that opened the resource, the Object Manager returns an opaque identifier called a handle. The handle's value is unique to the application that opened the resource, but it is not unique to the system across different applications. The application uses the handle to identify the resource in subsequent operations. When the application is finished with the object, the application closes the handle. The Object Manager uses reference counting to track how many system parts, including applications and Executive subsystems, are accessing an object that represents a resource. When the reference count goes to zero, the object is no longer in use representing the resource, and the Object Manager deletes the object (but not necessarily the resource).

The Object Manager implements NT's namespace to provide object identification. All shareable resources in NT have names that are rooted in this namespace. For example, when a program opens a file, the Object Manager parses the file's name to locate the file-system driver for the disk that stores the file. Similarly, when an application opens a Registry key, the Object Manager determines from the Registry key's name that the Configuration Manager must be called.

Most native system services that NT implements are resource related; thus, almost every system service invokes Object Manager functions. For example, services that open an existing resource call on the Object Manager to look up the resource name in the Object Manager namespace, ensure the caller has sufficient rights to open the resource, and allocate and return a handle to identify the open instance. Services that require a handle to a previously opened resource call the Object Manager to translate the handle to the object it represents.

The Object Manager calls other Executive subsystems when necessary. Every object type has functions that execute when NT performs particular operations on objects of that type. Thus, when the Object Manager creates a file object to represent an open file, the Object Manager invokes the I/O Manager's function for opening files. Similarly, the Object Manager creates an associated process object for an open process and invokes the Process Manager's function for opening processes.

Security Reference Monitor. The Security Reference Monitor is closely associated with the Object Manager. The Object Manager calls the Security Reference Monitor for an access check before letting an application open an object. The Object Manager also calls the Security Reference Monitor before it lets applications perform other operations on objects, such as reading from the object or writing to it.

The Security Reference Monitor implements a security model based on security identifiers (SIDs) and Discretionary Access Control Lists (DACLs). Every process in NT has an associated access token object that contains the SID identifying the user that owns the process and the SIDs of the groups the user belongs to. When a security check takes place, the SIDs in the access token of the process describe the user trying to complete an action on an object. Figure 2 gives an example of a DACL that does not let the process owner, Mark, read the object, although it lets the group the owner belongs to (Administrators) read from and delete the object.

NT's security model has a powerful capability that lets a process impersonate any user other than the user associated with the process. Server applications such as NT's built-in file server (SRV) rely heavily on impersonation. When a client on a different machine opens a file on the server, the server impersonates the client by temporarily adopting an access token that identifies the server as the remote client. NT creates the token on the server, but the token contains the client's SIDs. When the server opens the file, it invokes the Object Manager, which then calls the Security Reference Monitor to make the appropriate access check. The client can have more or less privilege than the server (the server might not be allowed to open the file), but impersonation lets the server temporarily identify as the client and thus hides the discrepancy.

DACLs specify the actions that particular SIDs can perform on an object. A DACL can contain any number of access control entries (ACEs), including no entries, that contain the information about actions SIDs can perform. Each ACE contains a SID, a flag specifying whether the ACE is of the deny type or allow type, and an operations mask (i.e., read, write, delete). Every object can have an ACE connected to it, such as the example in Figure 2 shows. NT references the ACE when a user attempts to open the object.

Given the access token object and the DACL in Figure 2, the Security Reference Monitor would deny Mark read access to the object, even though it allows members of the Administrator group read access to the object. The Security Reference Monitor would deny Mark read access to the object because the deny ACE is in front of the allow ACE in the DACL.

When a process wants to open an object, it must indicate the access it desires (e.g., read, write, delete). The Object Manager calls the Security Reference Monitor for an access check, and the Security Reference Monitor takes the desired access and the SIDs from the process' access token and goes through the object's DACL until it finds matching information. The Security Reference Monitor then looks at the DACL's ACE type: If the ACE is an allow type, the process can open the object. If the ACE is a deny type, the process cannot access the object. Two special cases exist in DACL security. First, users can fully access an object that does not have a DACL. Second, users cannot access an object with an existing but empty DACL.

When an object opens successfully, NT associates the access types granted to the calling process (and that match the access types specified during the open function) with the handle that NT returns to the calling process. When the calling process later performs an operation on the object, all the Security Reference Monitor must do is verify that the granted access types permit the operation--there is no need for the Security Reference Monitor to rescan the DACL.

The Security Reference Monitor also implements System Access Control Lists (SACLs), which are similar to DACLS. SACLs tell the system to log specific actions when particular users perform those actions. Systems administrators typically use SACLs to monitor and record attempted security violations.

Virtual Memory Manager. The Virtual Memory Manager has two main duties: to create and manage address maps for processes and to control physical memory allocation. NT 4.0 implements a 32-bit (4GB) address space; however, applications can directly access only the first 2GB, as Figure 3, page 62, shows. This portion of the address space is the user-mode half of the address map, and it changes to reflect the currently executing program's address map (e.g., Netscape, Notepad, Word). The 2GB to 4GB portion of the address space is for the kernel-mode portions of NT, and it doesn't change. NT 4.0 Service Pack 3 (SP3) and NT Server, Enterprise Edition 4.0, let administrators move the boundary in the address space so that user-mode applications can access 3GB of the map and kernel-mode components can use only 1GB.

The Virtual Memory Manager implements demand-paged virtual memory, which means it manages memory in individual segments, or pages. In x86 systems, a page is 4096 bytes; in Alpha systems, a page is 8192 bytes. The total memory applications require can exceed the computer's physical memory space. The Virtual Memory Manager stores the data that exceeds a computer's physical memory on the hard disk in page files. The Virtual Memory Manager transfers data to physical memory from a paging file when an application requests the data.

The Virtual Memory Manager has advanced capabilities that implement file memory mapping, memory sharing, and copy-on-write page protection. NT uses file memory mapping to load executable images and DLLs efficiently. In memory mapping, the Virtual Memory Manager learns through the operating system that a portion of a process' address map is connected to a particular file. When the process touches these portions of its address map (e.g., when it tries to execute code), the Virtual Memory Manager automatically loads the data into physical memory.

NT uses memory sharing to enhance physical memory use and to communicate between processes. For example, multiple instances of a program share a memory-mapped file image, and this sharing increases memory efficiency.

Copy-on-write is an optimization related to memory sharing in which several programs share common data that each program can modify individually. When one program writes to a copy-on-write page that it shares with another program, the program that makes the modification gets its own version of the copy-on-write page to scribble on. The other program then becomes the original page's sole owner. NT uses copy-on-write optimization when several applications share the writable portions of system DLLs.

The Virtual Memory Manager divides physical memory among several executing programs. It uses a function called working-set tuning to allocate additional memory to programs that require it and ensure that other executing programs have enough memory to keep running.

I/O Manager. The I/O Manager is responsible for integrating add-on device drivers with NT. Microsoft did not build support for various hardware devices into NT. Device drivers, which are dynamically loaded kernel-mode components, provide hardware support. A device driver controls a specific type of hardware device by translating the commands that NT and applications direct to the device and manipulating the hardware to carry out the commands. Microsoft supplies several device drivers for common hardware. If you purchase a nonstandard hardware item, the hardware vendor will provide a device driver for it.

The I/O Manager supports asynchronous, packet-based I/O. For example, when a program such as Lotus Notes reads from a file, the read-file system service, NtReadFile, allocates an I/O request packet (IRP) that describes everything a device driver needs to know to complete the program's request. The IRP information includes the location of the buffer into which the program must read the requested data, a pointer to the file object that represents the open file, the offset into the file where the data resides, and the amount of data the program must read. The I/O Manager takes the IRP and passes it to the device driver--in this example, a file system driver responsible for the target file. A file object represents an open file in this example, but a file object can represent a keyboard, a mouse, or an open network connection.

NT's developers designed IRPs to contain everything pertinent to an application's request to make implementing asynchronous packet-based I/O easier. For example, after the I/O Manager gives an application's request (and an IRP) to a device driver, the I/O Manager returns control to the application. The application can continue performing useful work while the device driver is transferring data and can check the device driver after the data transfer. Because asynchrony (or the overlapping of control between the application and the device driver) is sometimes difficult to program to, standard Win32 APIs hide the asynchrony. For example, when an application calls the Win32 function to read from a file, the application does not resume execution until after the function reads the data. Most advanced applications use Win32 APIs that expose the I/O Manager's asynchrony, because doing so can improve performance.

The I/O Manager supports 64-bit file offsets and layered device drivers. Using 64-bit offsets lets NT's file systems address extremely large files and lets disk device drivers address extremely large disks. Layering lets device drivers divide their labor. As the example in Figure 4 shows, the NTFS driver is layered above the fault-tolerant disk driver, which sits above a standard disk driver. As the I/O Manager processes requests, IRPs move down the layers, and the results pass back up from the bottom as each driver finishes its work.

Cache Manager. The Cache Manager works closely with the Virtual Memory Manager and file system drivers. The Cache Manager maintains NT's global (shared by all file systems) file system cache. The working-set tuner assigns physical memory to the file system cache. The NT cache is file oriented rather than disk-block oriented, as Windows 95 is. When the working-set tuner takes memory containing modified file data away from the Cache Manager, the I/O Manager invokes file systems that manage the moved files to write their data back to the disk.

Local Procedure Call Facility. NT's Local Procedure Call (LPC) Facility optimizes communications for applications, including operating system environments. The LPC function is based on two types of port object: connection ports and communication ports. A server creates a connection port, which a client connects to. After the client establishes that connection, the server creates a communication port, which the server and client transmit data through.

Three kinds of LPC exist: data copying, shared memory, and shared memory with event pairs (Quick-LPC). NT uses data copying for small messages (less than 256 bytes). One end of the communications link (client or server) copies a message to a port, and the other end of the link copies the message out of the port.

NT uses shared memory for messages larger than 256 bytes. In shared-memory LPC, the connected client and server share a region of memory. When one end of the communications link wants to send a message larger than 256 bytes to the other, it sends through the communications port a short message whose only function is to point to the location of the primary message in the shared memory. Shared memory avoids a copy operation but requires dedicated shared memory.

Win32 under NT 3.51 uses Quick-LPC. Win32 doesn't send messages through ports. Instead, one end of the communications link uses an event-pair synchronization object to signal the other end of the communications link that it has placed a message in shared memory. Using event-pair synchronization objects avoids the overhead of communicating through a port but as a trade-off has even higher resource overhead than other LPC methods.

Configuration Manager. Microsoft rarely discusses the Configuration Manager in its NT architecture documentation, but Configuration Manager is an important Executive subsystem. The Configuration Manager manages the Registry, and Win32 Registry API functions rely on NT native APIs the Configuration Manager implements. The Configuration Manager also exports functions to the I/O Manager, and the I/O Manager uses these functions to assign physical resources to device drivers. The Configuration Manager stores this assignment information in the Registry to detect and help prevent resource conflicts.

Process Manager. The Process Manager works with the Kernel to define process and thread objects. The Process Manager wraps the Kernel's process object and adds to it a process identifier (PID), the access token, an address map, and a handle table. The Process Manager performs a similar operation on the Kernel's thread object, adding to it a thread identifier (TID) and statistics. These statistics include process and thread start and exit times and various virtual-memory counters.

The Process Manager exports an interface that lets other Executive subsystems and user-mode applications manipulate processes and threads. For example, applications can access Process Manager functions to create processes, delete them, and modify their characteristics (such as their priority). You can access many Process Manager functions in user mode through system services.

Win32. Win32 consists of the messaging and drawing functions of the Win32 API. As I discussed in Part 1, in NT 3.51 these modules resided in user mode as part of the Win32 environment subsystem.

Plug-and-Play Manager and Power Manager. Two new Executive subsystems will debut in NT 5.0: the Plug-and-Play Manager and the Power Manager. The Plug-and-Play Manager notifies device drivers and the I/O Manager when hardware devices come online or are removed. The Power Manager maintains central control of the computer's power level, letting it shift into low power modes when possible. Both new subsystems work primarily with the I/O Manager and device drivers.

The Kernel
NT's Kernel operates more closely with hardware than the Executive does, and it contains CPU-specific code. NT's thread scheduler, called the dispatcher by NT's developers, resides in the Kernel. The dispatcher implements 32 priority levels, 0-31. The dispatcher reserves priority level 0 for a system thread that zeros memory pages as a background task. Priority levels 1 through 15 are variable (with some fixed priority levels) and are where programs execute; priority levels 16 through 31 are fixed priority levels that only administrators can access.

The NT dispatcher is a preemptive scheduler. The CPU's time is divided into slices called quantums. When a thread runs to the end of its quantum and doesn't yield the CPU, the dispatcher will step in and preempt it or schedule another thread of equal priority that is waiting to run (see "Inside the Windows NT Scheduler, Part 1," July 1997).

NT implements most synchronization primitives in the Kernel. NT has a rich set of synchronization types, including mutexes, semaphores, events, and spin locks. The Kernel implements and manages its own object types, and Kernel objects represent NT's synchronization primitives. In most cases, NT wraps Kernel objects with Executive objects so that applications can access them from user mode through the native API. As I described previously, the Process Manager wraps its process and thread objects around the Kernel's objects. NT stores all priority-related information and statistical information related to scheduling (e.g., context switches, user time) in the Kernel's objects.

The Kernel manages interrupt vectors (for more information on interrupt vectors, see my column "Inside NT's Interrupt Handling," November 1997). NT defines and implements IRQ levels in the Kernel.

The Hardware Abstraction Layer
The HAL is NT's interface to the raw CPU. Microsoft wanted to make NT portable across different processors. To make this portability feasible, NT's developers isolated as much CPU-specific code as possible into a separate, dynamically replaceable module, the HAL. The HAL exports a common processor model that masks the differences in various processor chips from NT. Device drivers use this common processor rather than a particular CPU type. Even different motherboards in the same processor family can differ significantly, but hardware vendors can ensure that NT will work with their boards by writing a custom HAL to work with NT.

A common difference between motherboards in the same processor family is that some are for multiprocessor systems and others are for uniprocessor systems. A multiprocessor HAL is different from a uniprocessor HAL. The multiprocessor-uniprocessor issue brings me to a little-known fact. Microsoft provides three versions of each NT release: the uniprocessor version, the multiprocessor version, and the debug version (or the checked-build version). In addition to having different HALs, uniprocessor and multiprocessor versions of NT have different ntoskrnl.exe images. The uniprocessor version of ntoskrnl.exe does not include code that is necessary for correct execution on multiprocessors. Microsoft provides the debug version of NT for device-driver developers. The debug version contains additional sanity checks and symbolic information not contained in the uniprocessor and multiprocessor versions of NT. Microsoft offers only one debug version of NT, which contains multiprocessor code and will work on multiprocessor and uniprocessor machines.

In a Nutshell
There you have it: NT's big picture in two articles. For more in-depth information, refer to previous columns in which I focused on subsystems or portions of subsystems (you can find these columns easily by searching the magazine archives on Windows NT Magazine's Web site, at http://www.winntmag.com). Another good source of information on NT subsystems is Helen Custer's Inside Windows NT (Microsoft Press, 1993). 


# [indows NT and VMS: The Rest of the Story](https://www.itprotoday.com/compute-engines/windows-nt-and-vms-rest-story)

Mark Russinovich | Nov 30, 1998

Is NT really new technology?

When Microsoft released the first version of Windows NT in April 1993, the company's marketing and public relations campaign heavily emphasized the NT (i.e., New Technology) in the operating system's (OS's) name. Microsoft promoted NT as a cutting-edge OS that included all the features users expected in an OS for workstations and small to midsized servers. Although NT was a new OS in 1993, with a new API (i.e., Win32) and new user and systems-management tools, the roots of NT's core architecture and implementation extend back to the mid-1970s.

And now...the rest of the story: I'll take you on a short tour of NT's lineage, which leads back to Digital and its VMS OS. Most of NT's lead developers, including VMS's chief architect, came from Digital, and their background heavily influenced NT's development. After I talk about NT's roots, I'll discuss the more-than-coincidental similarities between NT and VMS, and how Digital reacted to NT's release.

A Brief History of NT
NT's history is closely tied to that of David N. Cutler, NT's chief architect. After graduating from Michigan's Olivet College in 1965, Cutler worked for DuPont. Although computers weren't his first interest, he ran simulations on Digital machines as part of his job at DuPont. Before long, Cutler was knowledgeable about software and decided he wanted to develop OSs rather than application software. He joined Digital in 1971 and worked at Digital's famous "Mill" facility in Maynard, Massachusetts, developing OSs for the PDP-11 family. RSX-11M is the first OS in which Cutler incorporated major concepts and design principles that later surfaced in NT. RSX-11M is a PDP-11 OS Digital developed for industrial and manufacturing control.

In 1975, Digital realized that its competitors were developing 32-bit processors and that this technology would lure customers away from PDP's 16-bit architecture. Gordon Bell, a legendary figure in computer history and then vice president of engineering for Digital, drove the development of the 32-bit processor, which Digital eventually named VAX. By this time a star within Digital, Cutler was part of the initial VAX development team. Digital had charged Cutler, along with Dick Hustvedt and Peter Lipman, with designing VAX's OS, VMS. Digital's primary design goals for VAX hardware included backward compatibility with PDP-11 processors and enough flexibility that VAX could be the basis for low-end desktop workstations as well as enterprise-level servers. Digital also made VMS backward compatible with RSX-11M and designed VMS to run on different size machines. Of this development period, Digital states in its company history that it was "betting the business" on VAX and VMS. In an eerie echo of Digital's statement, Bill Gates recently claimed that Microsoft is "betting the business" on NT 5.0.

In 1977, Digital announced VAX-11/780 and VMS 1.0, making the first product shipments in 1978. As the project leader and one of VMS's main architects, Cutler continued work on successive releases of VMS, but he became restless at Digital. In 1981, Cutler threatened to leave Digital. To retain its star developer, Digital gave Cutler about 200 hardware and software engineers. Cutler moved his group to Seattle and started a development center. This elite group's goal was to design a new CPU architecture and OS that would lead Digital into the 1990s. Digital called the Cutler group's hardware project Prism, and its OS Mica.

In 1988, Digital executives cancelled Cutler's project and laid off many of its group members. Cutler decided to leave Digital, but before he could do so, Microsoft executives learned of the development and realized they had an ideal opportunity to hire Cutler. At the time Cutler left Digital, the release of VMS was version 5.0 (today's version is 7.1).

In August 1988, Bill Gates hired Cutler. One of Cutler's conditions for moving to Microsoft was that he could bring around 20 former Digital employees with him, including several Prism hardware engineers. Microsoft readily met this demand­the company knew hiring an OS architect of Cutler's stature was a coup, and few engineers had Cutler's track record. In addition, Gates felt that Microsoft's long-term future depended on the development of a new OS that would rival UNIX.

Microsoft's internal project name for the new OS was OS/2 NT, because Microsoft's intention was for the new OS to succeed OS/2 yet retain the OS/2 API as its primary interface. The success of Windows 3.0 in April 1990 altered Microsoft's thinking and its relationship with IBM. Six weeks after Microsoft released Windows 3.0, Microsoft renamed OS/2 NT as Windows NT, and designated the Win32 API (a 32-bit evolution of Windows 3.0's 16-bit API) NT's official API. Gates decided that compatibility with the 16-bit Windows API and the ability to run Windows 3.x applications unmodified were NT's paramount goals, in addition to support for portions of the DOS, OS/2, and POSIX APIs. From 1990 to NT's public release in August 1993, Cutler's team was in a mad dash to complete NT, and the project grew to involve more than 200 engineers and testers. Figure 1 shows a timeline of the major events in the history of NT.

TABLE 1: VMS and NT Terminology Translations
|*VMS Term* 	|*NT Translation*|
|--|--|
|Interrupt Priority Level (IPL) 	|Interrupt Request Level (IRQL)     |
|Asynchronous System Trap (AST) 	|Asynchronous Procedure Call (APC)  |
|Fork Procedure 	                |Deferred Procedure Call (DPC)      |
|I/O Request Packet (IRP) 	        |I/O Request Packet (IRP)           |
|Bug Check 	                        |Bug Check                          |
|System Service 	                |System Service                     |
|sys.exe 	                        |ntoskrnl.exe                       |
|Paged Pool 	                    |Paged Pool                         |
|Nonpaged Pool 	                    |Nonpaged Pool                      |
|Look aside List 	                |Look aside List                    |
|Section 	                        |Section                            |

NT and VMS
Most of NT's core designers had worked on and with VMS at Digital; some had worked directly with Cutler. How could these developers prevent their VMS design decisions from affecting their design and implementation of NT? Many users believe that NT's developers carried concepts from VMS to NT, but most don't know just how similar NT and VMS are at the kernel level (despite the Usenet joke that if you increment each letter in VMS you end up with WNT­Windows NT).

As in UNIX and most commercial OSs, NT has two modes of execution, as Figure 2 shows. In user mode, applications execute, and OS/2, DOS, and POSIX execute and export APIs for applications to use. These components are unprivileged because NT controls them and the hardware they run on. Without NT's permission, these components cannot directly access hardware. In addition, the components and hardware cannot access each other's memory space, nor can they access the memory associated with NT's kernel. The components in user mode must call on the kernel if they want to access hardware or allocate physical or logical resources.

The kernel executes in a privileged mode: It can directly access memory and hardware. The kernel consists of several Executive subsystems, which are responsible for managing resources, including the Process Manager, the I/O Manager, the Virtual Memory Manager, the Security Reference Monitor, and a microkernel that handles scheduling and interrupts. The system dynamically loads device drivers, which are kernel components that interface NT to different peripheral devices. The hardware abstraction layer (HAL) hides the specific intricacies of an underlying CPU and motherboard from NT. NT's native API is the API that user-mode applications use to speak to the kernel. This native API is mostly undocumented, because applications are supposed to speak Win32, DOS, OS/2, POSIX, or Win16, and these respective OS environments interact with the kernel on the application's behalf.

VMS doesn't have different OS personalities, as NT does, but its kernel and Executive subsystems are clear predecessors to NT's. Digital developers wrote the VMS kernel almost entirely in VAX assembly language. To be portable across different CPU architectures, Microsoft developers wrote NT's kernel almost entirely in C. In developing NT, these designers rewrote VMS in C, cleaning up, tuning, tweaking, and adding some new functionality and capabilities as they went. This statement is in danger of trivializing their efforts; after all, the designers built a new API (i.e., Win32), a new file system (i.e., NTFS), and a new graphical interface subsystem and administrative environment while maintaining backward compatibility with DOS, OS/2, POSIX, and Win16. Nevertheless, the migration of VMS internals to NT was so thorough that within a few weeks of NT's release, Digital engineers noticed the striking similarities.

Those similarities could fill a book. In fact, you can read sections of VAX/VMS Internals and Data Structures (Digital Press) as an accurate description of NT internals simply by translating VMS terms to NT terms. Table 1 lists a few VMS terms and their NT translations. Although I won't go into detail, I will discuss some of the major similarities and differences between Windows NT 3.1 and VMS 5.0, the last version of VMS Dave Cutler and his team might have influenced. This discussion assumes you have some familiarity with OS concepts (for background information about NT's architecture, see "Windows NT Architecture, Part 1" March 1998 and "Windows NT Architecture, Part 2" April 1998).

TABLE 2: Significant VMS and NT Similarities
|*VMS*| 	*NT*|
|-|-|
|Process scheduler implements 32 priority levels split into halves 	                                        |Process scheduler implements 32 priority levels split into halves|
|Process scheduler never lowers a process' priority below the priority level the application programmed 	|Process scheduler never lowers a process' priority below the priority level the application programmed|
|Uses boosting to handle CPU hogging 	                                                                    |Uses boosting to handle CPU hogging|
|Supports SMP 	                                                                                            |Supports SMP|
|Digital introduces kernel threads in VMS 7.0 	                                                            |NT 3.1 uses kernel threads|
|Relies heavily on memory-mapped files 	                                                                    |Relies heavily on memory-mapped files|
|Uses demand-paged virtual memory for physical memory management 	                                        |Uses demand-paged virtual memory for physical memory management|
|Uses working sets with a clock-based replacement algorithm 	                                            |Uses working sets with a clock-based replacement algorithm|
|Balance Set Manager uses swapping to handle the system's memory demands 	                                |Balance Set Manager doesn't use swapping|
|Supports a layered-driver model throughout the device driver stacks 	                                    |Supports a layered-driver model throughout the device driver stacks|
|Implements asynchronous packet-based I/O commands 	                                                        |Implements asynchronous packet-based I/O commands|
|Represents resources as objects managed by an Object Manager 	                                            |Represents resources as objects managed by an Object Manager|
|Security subsystem based on objects with access control lists (ACLs)                                       |Security subsystem based on objects with ACLs|
|MONITOR 	                                                                                                |Performance Monitor|
|BACKUP 	                                                                                                |NT Backup|

NT's processes are virtually the same as VMS's processes (Table 2, page 118, shows a comparison of VMS and NT processes). In NT, as in VMS, the process scheduler implements 32 priority levels. The process with the highest priority is always running, and processes with equal priority are scheduled in a round-robin pattern. The system considers the 16 high-priority levels realtime or fixed priorities, because the process scheduler doesn't manipulate priority in processes the system assigns to that range. The 16 low-priority levels (except 0, which the system reserves for the idle thread that executes when nothing else can) are dynamic because the scheduler, often with the input of device drivers, bumps priorities up in reaction to various conditions, such as when the process receives input from a device. This bumping procedure is called boosting. A defining aspect of the NT and VMS schedulers is that they never lower a process' priority below the priority level the application programmed. To handle CPU hogging, in which a process burns CPU cycles without regard to other processes in the system, the scheduler boosts the priority of starved processes that haven't executed for a defined period. Both VMS 5.0 and NT 3.1 schedulers support symmetric multiprocessing (SMP), which let them execute processes simultaneously on different CPUs in order to increase applications' performance.

A major difference between NT process management and VMS process management is that NT processes contain one or more threads of execution, and NT's scheduler gives CPU time to threads, not processes. Digital didn't introduce kernel threads into VMS until version 7.0 in 1995. This addition is one of several enhancements Digital has made to VMS since NT's release that appear to be in response to NT capabilities. In turn, Microsoft added lightweight user-mode threads support to NT 4.0 in 1996, which it copied from the VMS implementation of threads.

The memory managers in NT and VMS are also similar. Both OSs implement virtual memory address maps that the system splits between the currently executing application and the kernel. Both NT and VMS rely heavily on memory-mapped files, especially for mapping the code for executing applications and implementing copy-on-write functionality (because of VAX hardware limitations, VMS provides less efficient copy on demand funtionality). Physical memory management in NT and VMS relies on demand-paged virtual memory. VMS's memory manager assigns each process upper and lower limits (called working sets) for the amount of physical memory the system can assign them. This feature compartmentalizes applications so that an application with heavy memory demands minimally affects other processes. NT's memory manager incorporates working sets, along with many subtleties of the VMS working-set tuning algorithms.

As with the process manager, notable differences exist between NT's and VMS's memory manager. VMS's Balance Set Manager moves entire processes' memory footprints out of memory to paging files and back to memory in response to the overall memory demands of the system. Microsoft did not carry this mechanism, known as swapping, into NT's Balance Set Manager, although some of NT's Balance Set Manager's secondary responsibilities are the same as the secondary responsibilities of VMS's Balance Set Manager.

NT's I/O Manager is closely based on VMS's I/O Manager. Both OS's I/O Manager support a layered-driver model throughout the device driver stacks for different device types and implements asynchronous packet-based I/O commands, and its device drivers dynamically load and unload. Stackable and loadable drivers make NT and VMS very extensible. Either OS can divide functionality among several device drivers, with each driver implementing a different abstraction level. For example, the system can insert a fault-tolerant disk driver between a file system driver and a disk driver. This configuration lets the fault-tolerant disk driver receive a request the system sends to one logical drive (e.g., the C drive), then send the request to multiple physical drives to implement mirroring or striping. Asynchronous I/O enables applications and the kernel subsystems to initiate device requests and work while the requests are in progress, rather than wait idly for the requests to complete. NT's device driver architecture and interrupt-request priority scheme are based on VMS. Descriptions of these aspects of the I/O Manager are applicable to both OSs with little variation.

As you can see by comparing Figure 2 and Figure 3, page 117, the Executive subsystems exhibit the most significant resemblance between VMS and NT. But many minor similarities exist in which it is clear that Microsoft derived NT's capabilities from VMS. For example, both NT and VMS represent resources as objects that the system manages through an Object Manager, which implements uniform reference counting and accounting. The Object Manager regulates resource allocation and calls the Executive subsystem functions that request notification of certain object operations. VMS object management is not formalized, like it is in NT, and the VMS Object Manager is just a loose connection of functions. Microsoft extended NT's Object Manager so that it provides a uniform naming model for all kernel resources.

NT's security subsystem is based on objects with discretionary access control lists. DACLs determine which users can perform various operations on those objects. Digital added a DACL enhancement to VMS's security model in version 4.0 in 1984. Therefore, VMS's security implementation is the predecessor to NT's. Microsoft even included systems tools similar to VMS's in NT, including the Performance Monitor, which is based on MONITOR, the extensible VMS performance monitor. VMS included a utility called BACKUP long before Microsoft developed NT's backup utility.

"Why the Fastest Chip Didn't Win" (Business Week, April 28, 1997) states that when Digital engineers noticed the similarities between VMS and NT, they brought their observations to senior management. Rather than suing, Digital cut a deal with Microsoft. In the summer of 1995, Digital announced Affinity for OpenVMS, a program that required Microsoft to help train Digital NT technicians, help promote NT and Open-VMS as two pieces of a three-tiered client/server networking solution, and promise to maintain NT support for the Alpha processor. Microsoft also paid Digital between 65 million and 100 million dollars.

The Evolution of NT and VMS
Although Microsoft presents NT as a homegrown OS, NT is actually much older than its official 1993 birthdate. NT contains architectural and design influences from another company's flagship OS. Interestingly, throughout the 1990s, Digital introduced many NT features to VMS, and Microsoft has added VMS developments to NT. For example, VMS featured native clustering support in 1984, and 64-bit memory and system APIs in 1996. Microsoft did not introduce clustering support to NT until late last year­and only on a limited scale­and several years might pass before Microsoft releases 64-bit NT. Reciprocally, Microsoft released NT's first version with support for kernel-mode threads, system-wide event logging, and a configuration database called the Registry. VMS introduced kernal-mode threads in VMS 7.0 in 1995, and VMS 7.2 will include NT-style event logging and a Registry.

The saga goes on. Now that Compaq has acquired Digital, will VMS continue to evolve, or will NT seal the fate of its predecessor? One thing is certain: NT will continue to grow, leaving its origins further and further behind.

# [NT vs.UNIX: Is One Substantially Better](https://www.itprotoday.com/windows-78/nt-vsunix-one-substantially-better)
Mark Russinovich Nov 30, 1998

OS heavyweights go head-to-head for the enterprise

As Windows NT's share of the workstation and server market has eroded UNIX's dominance, discussion regarding which operating system (OS) is the superior one continues to rage. Many people argue with religious fervor that whichever OS they worked with first is best. In particular, some members of the UNIX camp seem to believe that if they argue loudly enough about the merits of UNIX, the tide of NT growth will slow. In light of this heated debate, it's ironic that both NT and UNIX have roots in the mid-1970s and that both were influenced by many identical theoretical OS concepts and principles (for more information about NT's history, see "Windows NT and VMS: The Rest of the Story..." page 114). No one should be surprised to discover that NT and UNIX have many similarities as well as differences.

In this article, I'll hold NT and UNIX side by side to compare their architectural subsystems, and I'll review the major features of each, touching on process management, scheduling, memory management, and I/O processing. I'll present the results of the most objective measurements available: industry-accepted benchmark results. Finally, I'll address the question any comparison begs: "Which OS is better?" No matter which side of the NT-UNIX debate you're on, you'll find some surprises waiting for you.

A Brief History of UNIX
Ken Thompson developed the first version of the UNIX OS in 1969 at Bell Laboratories. Dennis Ritchie joined Thompson early in the project and not only invented the C programming language but contributed to UNIX's design. Thompson and Ritchie rewrote UNIX in C, converting it from PDP-7 computer assembly language. This conversion was key to UNIX's later acceptance, allowing different computers to easily recompile and run the OS code. Some estimations hold that only 3 percent of UNIX's early source code was hardware-dependent, requiring programmers to rewrite it for porting to different computers.

UNIX underwent further development at Bell Labs, debuting to the research community in an academic conference paper in 1974. Bell Labs released the first version of UNIX, Version 6 (V6), in 1976. UNIX use quickly spread to many universities and research centers, fueled in part by the OS's portability to new and different computer systems. In 1978, Bell Labs released UNIX Time-Sharing System, Seventh Edition, a version of UNIX that had portability as a specific design goal. At the time, UNIX included many features that only mainframe OSs had, and its hardware resource requirements were relatively light. Thus, UNIX was an ideal OS for smaller systems that people commonly called minicomputers.

Bell Labs distributed UNIX with full source code. Researchers took this version of UNIX and developed custom versions with experimental design modifications. These customized versions of UNIX fueled UNIX's market acceptance because they made integrating OS innovations easy for developers. However, this heritage is a mixed blessing that the UNIX community still wrestles with today. Within a year after Bell's release of UNIX's full source code, three or four major UNIX variants began to evolve.

In the early 1980s, three major branches grew on the UNIX tree: UNIX System III from Bell Lab's UNIX Support Group (USG); UNIX Berkeley Source Distribution (BSD) from the University of California at Berkeley; and a version of UNIX that ran on the x86 processor family, Microsoft's XENIX. Are you surprised to learn that Microsoft had a version of UNIX? If so, you'll be even more surprised to learn that XENIX had the largest installed base of any UNIX system during the early 1980s. Microsoft sold XENIX to The Santa Cruz Operation (SCO) in 1995, when Microsoft purchased a portion of SCO. Throughout the 1980s, the UNIX market fragmented further, with versions of the OS splitting several times; in many cases, descendant branches of a version merged with separate UNIX lines.

UNIX's fragmentation spawned many variant OS interfaces, and the result of the variation was that any particular version's programs did not port to other versions. To stem this trend, a group of vendors, working through the Institute of Electrical and Electronics Engineers (IEEE), formulated the POSIX standard. A major milestone in this effort was the creation of a definition for a standard system-call interface, or UNIX API, in 1988. This API was POSIX 1003.1. The POSIX standards have grown to include other aspects of UNIX design, including realtime processing capabilities, user interfaces, and application suites. To the detriment of standardization, however, other organizations were establishing UNIX standards in the late 1980s. The X/OPEN Group, consisting primarily of European vendors, published a standard specification called the X/OPEN Portability Guide in 1987.

Although most UNIX variants today support either the POSIX or X/OPEN standard, every UNIX vendor has tried to differentiate its offering with a proprietary interface, applications, and architecture. Several dozen widely used versions of UNIX exist today, and Sun's Solaris, HP's HP/UX, and IBM's AIX hold the largest shares of the commercial UNIX market. The Linux version of UNIX, which has become the centerpiece of the so-called open source movement, made headlines in the trade press recently. Linux is a homegrown UNIX variant designed by Linus Torvalds and further developed by hundreds of independent developers around the world. In 1993, Linux (including source code) became available on the Internet for free download. An ironic twist to the tale is that only a few years ago the computer industry press debated whether NT could challenge UNIX's market share--today the argument is whether Linux can be the UNIX challenger to NT. Recent market-research reports show that Linux is the only server OS besides NT to gain market share. Other research reports 11 million NT installations, whereas the Linux community reports an estimated Linux installed base of between 5 and 7 million. (To read more about the Linux challenge to NT, see the sidebar "Linux and the Enterprise" and David Chernicoff, "Walking the Walk and Talking the Talk," November 1998.) The bulk of those NT installations are in the business community, whereas a large percentage of the Linux installations are still in the realm of the computer hobbyist. This situation might change, however, with the recent release of Oracle8 for Linux and Netscape's and Intel's investment in Red Hat Software, a commercial provider of Linux software.

NT and UNIX
NT's roots extend back to 1977 and Digital Equipment's release of VMS 1.0. Many core members of the future NT design team left Digital in 1988 to join Microsoft, which released NT's first version, Windows NT 3.1, in 1993. Thus, NT and UNIX have been evolving since the mid-1970s, and trends in academic OS research have influenced each OS. In addition, both OSs have similar design goals: portability, extensibility, and the ability to run on computers ranging from desktop PCs to departmental servers.

Internally, NT is similar to VMS, but how closely do NT's capabilities and features match those of UNIX? Shedding light on this question is difficult, because even the top three UNIX market share leaders--Solaris, HP/UX, and AIX--are in many ways as different from one another as each is from NT. Thus, there is no definitive "UNIX" to compare with NT. Therefore, I'll use traditional or prevalent UNIX features and implementations for each UNIX subsystem in the following comparison of NT and UNIX. I'll draw from the market leaders and three other UNIX variants: Linux, BSD 4.4, and Digital UNIX.

The OS architecture of most versions of UNIX is similar to that of NT. Figure 1 and Figure 2 show the UNIX and NT architectures, respectively. (To explore NT's architecture in depth, see "Windows NT Architecture, Part 1," March 1998 and "Windows NT Architecture, Part 2," April 1998.) Both OS architectures have two modes of operation: user mode and kernel mode. Familiar applications such as word processors and database programs execute in user mode. User mode is nonprivileged, which means that the system restricts programs operating in user mode from directly accessing hardware or resources belonging to other programs. Most of the OS code executes in kernel mode. Kernel mode is privileged, which means that code running in kernel mode can access hardware and resources belonging to any application, with few limitations.

A major difference between UNIX's and NT's architecture is that UNIX does not incorporate its windowing system--the subsystem that manages GUI resources for applications--into kernel mode, as does NT 4.0. Instead, the UNIX windowing system is an add-on user-mode application that its developers wrote using publicly defined UNIX APIs; consequently, third-party products can replace UNIX's windowing system. However, the majority of the UNIX community has adopted MIT's X-Windows as a de facto, if not official, graphical interface standard. Before NT 4.0, the NT windowing system was a user-mode implementation, but Microsoft found that the performance of graphics-intensive applications improved when the windowing system operated in kernel mode.

Another difference between the OS architectures is that UNIX applications can call kernel functions, or system calls, directly. In NT, applications call APIs that the OS environment to which they are coded (DOS, Windows 3.x, OS/2, POSIX) exports. A kernel system-call interface provides APIs for managing processes, memory, and files. The NT system-call interface, called the Native API, is hidden from programmers and largely undocumented. The number of UNIX system calls is roughly equal to the number of Native APIs, around 200 to 300. The API that UNIX applications write to is the UNIX system-call interface, whereas the API that the majority of NT applications write to is the Win32 API, which translates many Win32 APIs to Native APIs.

In the following comparison of NT and UNIX subsystems, I'll contrast the way each OS names internal resources, implements processes and threads, and manages virtual and physical memory. I'll also compare and contrast UNIX's and NT's security model, file-system data caching, networking architecture, and extensibility.

Namespace and object management. An OS namespace gives applications the ability to identify and share resources. Perhaps the most visible part of an OS namespace is the file-system namespace, which in UNIX includes names such as /usr/mark/bin/csh and in NT includes names such as C:\BIN\CSH.EXE. Other resources that require naming so that two or more applications can uniquely identify them for sharing include synchronization resources (e.g., mutexes, semaphores, notification events) and shared memory.

NT's Object Manager subsystem implements NT's namespace. The Object Manager is a collection of kernel functions that provide uniform resource tracking, naming, and security to applications and other kernel-mode subsystems. Kernel subsystems define Object Manager objects to represent the subsystems' resource types, and rely on the Object Manager's support routines for naming and security. Thus, the Object Manager represents processes as process objects, files as file objects, and semaphores as semaphore objects. The Object Manager's object-tracking mechanism notifies a subsystem that owns an object when applications close, open, or query the object. The Object Manager notifies subsystems via method functions, which the subsystems register when defining an object type. In response to Object Manager notification, a subsystem can perform actions particular to the type of object the subsystem is managing.

The Object Manager namespace allows for the naming of any object and also allows entrance to the familiar file-system namespace, which the I/O Manager subsystem implements. The file-system name C:\BIN\CSH.EXE is the application-friendly name of the file csh.exe. In the NT kernel, csh.exe's name is similar to \Device\Harddisk0\Partition1\BIN\CSH.\Device\Harddisk0\Partition1 is the name of a device object in the Object Manager namespace; this device is a doorway to the I/O Manager's file-system namespace. An object named \Registry in the Object Manager namespace functions as a similar doorway to the Registry namespace.

In the NT object model, device drivers can easily implement objects in the namespace that represent nonstandard resources. For example, a device driver can create an object called \Proc that, after an application reads it, returns information about the active processes in the system.

UNIX's object-tracking mechanism is not as formal as NT's mechanism. UNIX's namespace centers on the OS's file system and grew out of the original UNIX file-system namespace. Data structures called vnodes (in some older UNIX variants, inodes) are the equivalent of NT Object Manager objects and represent files as well as shared memory, synchronization objects, and nonstandard resources. (I use the term vnode to refer to inodes and vnodes in this discussion.) The example UNIX file-system name I gave earlier, /usr/mark/bin/csh, is not translated in any way in the kernel. However, any component of the name can serve as a link to a different namespace that a particular file-system driver implements. Traditionally, the /dev directory in the UNIX namespace contains objects that are doorways to non-file-system namespaces (all namespace providers in UNIX act like file-system drivers). Thus, /dev/proc is usually a doorway to a process file-system driver. An application that reads from this pseudofile can obtain information about the processes currently running on the system.

The file-system support code in the UNIX kernel notifies file-system drivers of actions that applications perform on vnodes that the file systems manage. The support code performs this notification by calling functions registered in a table that the file system associates with the vnodes the file system owns. For example, the support code calls the file system whenever an application opens, closes, or deletes an object represented by the file system's vnode.

The designs of NT's and UNIX's namespace and resource tracking are similar in their goals and even in their implementation. Both designs use a hierarchical namespace similar to a traditional file-system namespace, and both implement object notification functions and reference-count tracking. Similar object support mechanisms follow from NT's and UNIX's common goal of providing a generalized resource-tracking infrastructure that is integrated with the namespace.

Process management.Process management encompasses both the way an OS defines and implements user applications, and the method the OS uses to divide CPU time (or the CPU resource) between multiple active applications. NT and UNIX are time-sharing OSs that try to divide CPU time fairly between applications competing for the CPU. Neither OS is suitable for environments that have strict application-responsiveness guarantees. Both OSs, however, try to define execution modes that are more responsive than their standard modes so that each OS can execute applications with "soft realtime" requirements with some degree of efficiency. The way in which an OS implements its process management has a significant impact on the OS's ability to scale on multiprocessor systems.

NT defines an application using a process object, which serves as a container for all information about the application. The process object includes a memory space definition that contains the application's code and data, a table that identifies which resources the application is accessing, statistical information regarding the application's execution, the identity of the user the application is associated with, and one or more threads of execution. The NT scheduler divides time between threads (not between applications). A thread is a kernel execution state that determines where in an application the system should execute code on behalf of the thread. Applications can create additional threads, and all of a particular application's threads share the application's resources and memory space.

The NT scheduler always attempts to give CPU time to the highest-priority thread available. The scheduler defines two scheduling classes: dynamic and realtime. Threads executing with priorities in the dynamic half of the priority spectrum have a priority value of between 1 and 15 (higher numbers correspond to higher priorities). This range is called dynamic because the scheduler can adjust the priorities of dynamic threads by temporarily boosting their priority values according to various events, such as the receipt of input from the keyboard. The priority values of threads in the realtime range are between 16 and 31. Realtime priority values are fixed; the scheduler does not adjust these priority values. Typically, only a few OS-owned threads execute in the realtime range. When the scheduler gives a thread a turn on the CPU, the length of the turn, which is called a quantum, lies in the range of 20 to 120 milliseconds. When a thread's quantum is over, or if the thread cedes its turn early, the scheduler schedules other threads of the same priority (if any exist) in a round-robin manner.

NT supports symmetric multiprocessing (SMP). In SMP processors, all CPUs are identical and have equal access to memory and I/O peripherals. Internal data structures limit NT to using a maximum of 32 processors, but licensing limitations usually restrict the number of processors to 8 or fewer. NT rarely runs on systems with more than 8 CPUs. An important characteristic of the NT scheduler is that it can fully preempt the kernel. For example, even if a thread is executing in the kernel, the scheduler can end that thread's turn and schedule another thread in its place. Further, multiple threads can actively execute kernel code on separate CPUs simultaneously. These two functions--kernel preemption and execution of kernel code on separate CPUs--are necessary for multiprocessor scalability.

Process management in most modern UNIX variants is similar to NT process management. Both OSs use a process data structure to define applications. This data structure encompasses roughly the same components that an NT process encompasses. These components include an address space, resource handles, and statistics. In addition, modern variants of UNIX divide CPU time between kernel-mode threads and define processes as having at least one thread.

UNIX schedulers usually implement three priority classes--realtime, system, and dynamic--that span priority numbers from 0 to 100. Low priority numbers identify higher-priority threads. The UNIX realtime and system priority classes are similar to the NT realtime class in that the UNIX scheduler does not modify the priorities of threads executing in these classes. The UNIX scheduler can lower the priority (i.e., raise the priority number) of threads that execute in the dynamic class when the threads continue to execute without voluntarily giving up a turn. The length of a UNIX scheduler's quantum is similar to the length of NT's quantum: from ten to several hundred milliseconds.

UNIX's multiprocessor support is more advanced than NT's. Several variants of UNIX, including HP/UX, Solaris, and AIX, run on large SMPs with 32 or more CPUs. Some versions of UNIX can run on asymmetric multiprocessors. Similarly to NT's kernel, the kernels of most UNIX implementations are fully preemptible and simultaneously executable on different CPUs.

Process management in NT and UNIX have much in common: Both OSs define applications as processes, and both OSs' processes have one or more kernel threads. The differences between NT's and UNIX's process management involve differing priority schemes and subtleties in scheduling algorithms. One notable difference is that NT boosts the priorities of dynamic threads in response to events such as input, whereas UNIX depresses dynamic threads' priorities as the threads consume the CPU. Both OSs try to treat CPU-bound and I/O-intensive threads fairly with respect to other threads, but each OS goes about this task differently.

Memory management.An OS's memory manager is responsible for defining virtual address spaces for application code and data, and for sharing the physical memory resource of the computer among different applications. A memory manager should apportion more physical memory to applications that have heavy memory requirements while remaining responsive to the needs of all applications. A memory manager's policies and implementation determine how well the OS supports multiple simultaneously executing applications.

NT's Memory Manager defines a 32-bit virtual address map, which Figure 3 shows, that spans 2GB to 4GB.The space is split between user-mode application code and data and kernel-mode code and data. Usually, NT assigns the low 2GB (i.e., 0GB to 2GB) of the virtual address space to the user mode; this space is called the user space. NT assigns the upper 2GB (i.e., 2GB to 4GB) of the virtual address space to the kernel mode; this space is called the kernel space. NT does not give applications direct access to the kernel-mode portion of the address space; some versions of NT (e.g., NT Server 4.0, Enterprise Edition) support a switch that changes the virtual address space division to 3GB for the user space and 1GB for the kernel space. The kernel space permanently maps the NT kernel and device drivers, but user-space mapping changes to reflect the process address map of the currently executing thread. For example, if a Microsoft Word thread executes, Word's code and data map into the user space. However, if the scheduler switches to a Lotus Notes thread, the NT Memory Manager updates the user space with Lotus Notes' code and data.

NT's Memory Manager implements demand-paged virtual memory, in which the Memory Manager brings code and data into physical memory as an application accesses the code and data. The Memory Manager implements the required features of a modern OS, including allowing applications to share portions of their address maps with other applications; enabling copy-on-write, for efficient implementation of shared memory when changes need to remain private to the application making the changes; and enabling memory-mapped files. Memory-mapped files let applications efficiently read and modify file data; any changes the application makes to the mapped file automatically reflect back to the file's on-disk image.

NT bases physical memory management on assigning each application upper and lower limits on memory. In NT parlance, an application's allotted amount of physical memory is its working set. When an application reaches its working set's upper limit and accesses more data or code, the Memory Manager uses a least-recently-used (LRU) algorithm (the clock algorithm) to find data in the working set to replace. When the Memory Manager must bring in data or code from a file on disk, it will typically bring in slightly more than the application requests. This optimization is called clustering.

Most UNIX memory managers are generally similar to NT's Memory Manager. UNIX memory managers define a virtual address space split between user space and kernel space. Some UNIX variants implement the same 2GB-2GB or 3GB-1GB user-space and kernel-space split NT implements. Other UNIX variants, however, give the majority of the address space to applications, reserving only a few hundred MB for the kernel. Similarly to NT's Memory Manager, UNIX memory managers implement demand-paged virtual memory and support shared memory, copy-on-write, and memory-mapped files.

UNIX memory managers differ from the NT Memory Manager in that they manage memory globally--they do not constrain individual applications to specific upper and lower limits. In addition, when a UNIX application accesses code or data that must be brought into memory, the memory manager uses the clock algorithm or a close variation to find data or code that belongs to any application--not necessarily the application performing the access--to replace the code or data it maps to memory. This policy lets memory-intensive UNIX applications starve other programs, which can lead to a performance bottleneck known as thrashing. To combat thrashing, most UNIX variants have a swapper--a background process that can send entire applications out of memory. The swapper will thus swap out applications to relieve a thrashing condition. Finally, UNIX clusters memory-oriented file accesses in the same way NT does.

A side-by-side comparison of NT and UNIX memory management reveals many similarities: Both implement demand-paged virtual memory, both have similar address-space definitions, and both use variants of the clock algorithm for in-memory data replacement. The differences between the OSs include the fact that NT manages memory on a per-process basis, whereas UNIX manages memory globally. In addition, UNIX relies on swapping to avoid thrashing, whereas NT avoids such a condition through per-process management. Bigger differences between the OSs are that several variants of UNIX, including Solaris, HP/UX, and Digital UNIX, can make use of 64-bit address spaces on 64-bit processors. A 64-bit version of NT won't be available for at least a year. Using 64-bit address spaces can boost the performance of data-intensive server applications such as database servers.

Security.A modern OS must provide protection for its users' sensitive data, and the features of its security subsystem play a major role in determining the security rating an OS achieves. NT's security capabilities have earned it a C2-capable rating (as a standalone nonnetworked system), which the industry considers the minimum level required of a modern OS. NT's security model relies on the concepts of users and groups of users. NT defines users as having certain privileges, such as the ability to shut down the computer, back up files, or load device drivers. NT users can belong to any number of groups. The NT Object Manager's centralized security support means that the Object Manager can implement any object--including synchronization objects, shared memory, and files--with security.

NT specifies an object's security settings by implementing access control lists (ACLs). An object's ACL can have any number of access control entries (ACEs), and each ACE specifies which actions a particular user or group can perform on the object. Administrators can use this flexibility to precisely control access to an object. As part of fulfilling C2 security requirements, NT can audit successful and failed attempts to access an object. NT implements auditing control in a manner similar to the way it implements access control--by assigning objects auditing ACEs that define which user or group actions generate an audit record. A powerful aspect of the NT security model is that server applications can maintain security information for their privately defined objects and can use security APIs to validate client access to the objects.

In many types of NT drivers, a driver writer implements only a portion of the driver. The remaining portion of the driver, which performs functionality common to all drivers of its particular type, is a standard component of NT. This architecture is the class, port, miniport architecture, and simplifies the implementation of many device driver types. NT 5.0 will fully support plug-and-play devices through enhancements to its I/O architecture. These enhancements will let NT 5.0 dynamically detect, load, and assign device drivers' hardware resources optimally.

UNIX's I/O model focuses on vnodes, the UNIX equivalent to NT file objects. The UNIX I/O subsystem routes requests that applications direct at vnodes to the device driver with which the particular vnode associates. UNIX does not describe its I/O requests in discrete packets, and the majority of UNIX implementations do not support a layered driver model (UNIX sometimes supports layered I/O in a specialized network driver model it calls STREAMS). Traditional UNIX supports only synchronous I/O, and UNIX drivers process all levels of abstraction. Several modern UNIX variants, including the leading commercial offerings, extend the traditional I/O model to achieve asynchronous I/O processing capability. The majority of UNIX implementations split interrupt processing into two phases in the same way NT does, and most of these implementations have an interrupt priority scheme that is virtually identical to NT's.

Modern NT and UNIX have similar I/O architectures that are superior in many ways to the I/O model of older UNIX implementations. However, the NT I/O model's layered architecture, which is applied fairly uniformly across device types, makes NT extremely extensible--NT can add new functionality or capabilities to existing device drivers simply by inserting new drivers above or below the existing drivers in a request stack. In addition, NT has a larger API for device drivers to use than most UNIX offerings have, which lets NT add extensions to the base OS.

The traditional UNIX security model is much less powerful. Similarly to NT, UNIX can assign users group membership, but UNIX groups have no security privileges. Instead, UNIX relies on a special user account, or root, that can bypass all security settings. Because UNIX does not employ an application-accessible security, UNIX applies security only to files. UNIX defines a file as having an owning user and group, and flags identify what actions out of read, write, and execute the file's user, group, and everyone else can perform on the file.

The lack of ACLs and auditing prevent traditional UNIX from achieving a C2-capable security rating. This situation has led virtually every major UNIX vendor to create a proprietary UNIX version that implements these features, mirroring NT's security model. For example, Digital has a C2-capable version of Digital UNIX called Trusted Digital UNIX, and Sun developed Trusted Solaris. Some UNIX variants, such as a version of HP/UX that earned a B2 rating, have earned security ratings higher than C2.

Although NT's security model is superior to traditional UNIX's security model, modern UNIX implementations match NT in security robustness and classification. One notable exception is Linux, which does not implement several requirements of a C2-capable rating, including ACLs and auditing.

I/O.The I/O subsystem plays a major role in determining an OS's scalability and performance. The architecture of an OS's I/O model defines the efficiency with which device drivers interact with hardware to transfer application data to and from peripherals such as storage devices and network cards, and the I/O subsystem must aid drivers in quickly responding to device interrupts. Lack of flexibility in an OS's I/O model can make augmenting existing drivers with new functionality difficult.

NT bases its I/O model (which closely resembles VMS's I/O model) on the file object. Applications direct I/O requests at a file object representing a device resource, and the NT I/O Manager passes the requests to the resource's associated device driver. A powerful aspect of NT's I/O architecture is that drivers can layer on one another. Layering lets a driver receive a request from an application and pass the request to another driver for further processing, instead of entirely processing the request itself. Multiple drivers that work together to process I/O process requests at different levels of abstraction.

Figure 4 shows a typical example of NT's layered I/O model. In this example, three drivers work together to process file-system requests. The top-level driver understands file-system on-disk layout, so it takes requests that are file-oriented and translates them into requests that are disk-oriented. The middle-level driver receives the disk-oriented requests and converts them into one or more requests specifying physical media, mirroring or striping the request to achieve fault tolerance. The bottom-level driver simply transfers data to or from a physical device.

Another defining characteristic of the NT I/O model is that NT describes I/O requests in discrete packets of information called I/O request packets (IRPs). The I/O subsystem supports fully asynchronous I/O, which is necessary for high-performance I/O-intensive applications. NT bases its interrupt architecture on abstract interrupt priority levels (IPLs--NT's term for IPL is Interrupt Request Level--IRQL) and splits interrupt processing into two phases. In the first phase, a driver's interrupt service routine (ISR) responds to an interrupt when the system has a high IPL. The ISR performs minimal processing and notifies the I/O subsystem to invoke the driver at a later point, when the system's IPL is lower. At this time, the second phase, in which the bulk of the I/O processing occurs, begins. This two-phase processing scheme keeps periods when interrupts are disabled to a minimum, so that the system is as responsive to devices as possible.

Miscellaneous comparisons.Other significant areas in any NT-UNIX comparison are file systems, networking support, and portability. As in the other areas I've discussed, NT and UNIX have very similar file system and network driver architectures. Both NT and modern versions of UNIX implement virtual-file caches and support zero-copy file serving. In their network drivers, both OSs divide work between network adapter drivers, network protocol drivers, and a network API layer.

Where NT and UNIX differ is in which file-system types, networking APIs, and networking protocols each OS supports. However, even different versions of UNIX vary in these areas. All UNIX versions support at least one file system that is comparable in capability to NTFS, and all UNIX versions support the socket API and the TCP/IP protocol, as NT does with its Winsock API and TCP/IP stack.

It sometimes seems as if NT gets less portable by the day. NT currently supports the Alpha and x86 architectures. Although you can probably find a version of UNIX that runs on any given hardware platform, the leading commercial UNIX releases are even less portable that NT, running only on their vendors' proprietary CPU type, and sometimes on the x86 as well. For example, Sun Microsystems developed Solaris for the SUN Sparq chip but ports Solaris to the x86. IBM's AIX runs only on the PowerPC chip, which IBM codeveloped with Motorola.

Which OS Is Better?
I'm sure that most of this article's readers could happily make their own proclamations as to which OS is superior to the other. However, the only truly objective measure available is the results of industry-accepted benchmark tests. Therefore, here are the best results NT and UNIX achieved on two major benchmarks. The first benchmark is the System Performance Evaluation Consortium's (SPEC's) SpecWeb Web-serving benchmark, and the second benchmark is the Transaction Processing Council's (TPC's) TPC-C database-serving benchmark. Major industry vendors formed SPEC and TPC in the 1980s to independently define and validate benchmarks to compare systems with one another as objectively as possible. The benchmark results hardware and OS manufacturers submit to SPEC and TPC are generally the best-of-breed numbers for hardware and OS platforms. Companies that can claim leading numbers on a benchmark gain prestige, so most manufacturers make significant investments of time and energy to produce and report high numbers.

You can view the complete listing of approved SPEC benchmark results at http://www.specbench.org, and the complete listing of TPC results at http://www.tpc.org. I drew the results I relate from these sites. These results are current as of mid-October. Rather than only reporting the world record for each benchmark, these results show how NT and UNIX compare on uniprocessor and multiprocessor systems.

Graphs 1, 2, and 3, page 130, show the SpecWeb results. These graphs' vertical axes represent the number of Web requests the tested systems serviced per second. NT holds the SpecWeb record for 1-way processors, as Graph 1 shows. UNIX takes the lead on the SpecWeb results for 2-way and 4-way systems, as Graph 2 and Graph 3, respectively, show. UNIX also takes the absolute world record: 13811 on a 16-way HP/UX system.

Graphs 4, 5, and 6, page 131, show the TPC-C results. The vertical axes on these graphs represent the number of database requests the tested system serviced per minute. Graphs 4, 5, and 6 also show cost in dollars per transaction, which TPC calculates based on the total cost of the hardware and software a system uses to achieve the benchmark. Graph 4 and Graph 5 show that NT has the advantage in the TPC-C results for dual processors and 4-way machines, respectively (companies don't usually report uniprocessor TPC-C numbers). UNIX has the edge in the TPC-C results for 8-way systems, as Graph 6 shows. UNIX again takes the TPC-C world record with 102541, which it achieved with a 96-way Digital UNIX system. This world record puts the best NT number (16257, achieved with an 8-way system) to shame, as would many scores achieved by UNIX clusters. However, NT's cost per transaction is consistently half that of comparable UNIX machines, regardless of the number of processors.

What these benchmarks show is that, contrary to popular belief, NT can compete head-to-head with UNIX on high-end servers. The results also demonstrate that NT can scale well to four processors on enterprise-level applications. The results show, too, that NT is not a contender on systems with more than four CPUs, and that UNIX clustering solutions are far ahead of anything NT has to offer. However, NT is a relative newcomer to multiprocessors and clustering. Microsoft has recently begun to focus on multiprocessing and clustering capabilities as part of the company's plan to move NT into the high-end enterprise-scale arena. It won't be long before UNIX finds NT on its heels.

So Which OS Is Really Better?
The fact that an OS implements a certain feature in a particular subsystem or achieves a certain number on a benchmark doesn't necessarily make that OS good or bad, better or worse. Many factors go into determining whether one OS is better than another. Most of these factors depend on the importance of certain attributes I haven't discussed, and include things such as application availability, initial cost, cost of support and maintenance, compatibility with existing infrastructure, and ease of use. The point is that good and bad are highly subjective terms, and one person's or organization's definition of those terms won't necessarily be the same as another person's or organization's definition. However, trends in the marketplace over the past few years are making one thing perfectly clear: NT is here to stay, and it is becoming the choice of a new generation of IT professional.


